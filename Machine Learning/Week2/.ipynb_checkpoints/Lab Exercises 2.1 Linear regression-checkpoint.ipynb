{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Exercises Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Overfitting and Cross Validation\n",
    "\n",
    "Use `LinearRegression` from scikit learn to produce Fig 1.12 (a) below from *A First Course in Machine Learning*, using the Olympic data. \n",
    "\n",
    "Hints:\n",
    "- you will need to create a validation set, using the data from 1980 onwards (the last 8 rows in the dataset)\n",
    "- all the rest of the data should be used for training.\n",
    "- the *Training Loss* on the y-axis is **not** the mean squared loss, but the *total* squared loss (I don't think this is said anywhere in the book though!)\n",
    "- scale the data as was done in the lecture, to avoid problems with high-order polynomials\n",
    "\n",
    "![FromSimpleToPoly](Images/FCML_Fig1_12_cite.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1b\n",
    "\n",
    "Repeat the above making use of:\n",
    "\n",
    "`from sklearn.preprocessing import PolynomialFeatures`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "See also here for a worked example:\n",
    "https://machinelearningmastery.com/polynomial-features-transforms-for-machine-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Nonlinear response from linear model\n",
    "\n",
    "Use `LinearRegression` from scikit learn to produce Fig 1.11 below from *A First Course in Machine Learning*, using the Olympic data.\n",
    "\n",
    "Hints: \n",
    "- You will need to create a design matrix $\\mathbf{X}$ containing 3 columns: a column of 1s; a column containing $x$ (the year); and a column containing $\\sin \\left(\\frac{x-a}{b}\\right)$ (where $a = 2660$ and $b = 4.3$).\n",
    "- All data is used for training in this plot (i.e. none is withheld in a validation set).\n",
    "\n",
    "![FromSimpleToPoly](Images/FCML_Fig1_11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate Figure 1.17 from *A First Course in Machine Learning*.  It is fitting a fifth order polynomial to six points, with regularisation.\n",
    "\n",
    "Use the points:\n",
    "\n",
    "$(0,-3.2),(0.2,-4.8),(0.4,3),(0.6,-0.2),(0.8,1),(1,-3)$\n",
    "\n",
    "Use `Ridge` from:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
    "\n",
    "Also you may want to try out:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV\n",
    "\n",
    "Note what we have called $\\lambda$, is referred to as `alpha` in `Ridge` in scikit learn.\n",
    "\n",
    "![FromSimpleToPoly](Images/FCML_Fig1_17_cite.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Multiple Linear regression and Feature Selection\n",
    "\n",
    "Use `LinearRegression` from scikit learn to predict the quality of wine in the wine data set from last week.\n",
    "\n",
    "Start by building a model that includes all the features.\n",
    "\n",
    "Then use Recursive Feature Selection in scikit learn to build a model with the best *five* features.\n",
    "\n",
    "Suggested reading:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE\n",
    "\n",
    "https://machinelearningmastery.com/rfe-feature-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Some reading involving linear regression and optimization\n",
    "\n",
    "Read: https://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/\n",
    "\n",
    "This describes an implementation of multiple linear regression, as well as providing a brief intro to a gradient descent optimization algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
